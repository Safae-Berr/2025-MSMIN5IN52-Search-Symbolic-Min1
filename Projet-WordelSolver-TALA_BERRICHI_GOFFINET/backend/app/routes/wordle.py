from fastapi import APIRouter, HTTPException
from pydantic import BaseModel
from typing import Optional
from app.data.load_fr_word import load_fr_words
from app.data.load_en_word import load_en_words
from app.services.wordle_solver import HybridWordleSolver
from app.models.schemas import Feedback
from app.services.llm_service import GeminiLLM
from app.models.schemas import Feedback, WordSuggestionsRequest


router = APIRouter()

# Charger dictionnaires
words_fr = load_fr_words()
words_en = load_en_words()

solver_fr = HybridWordleSolver(words_fr)
solver_en = HybridWordleSolver(words_en)
llm_service = GeminiLLM()

class WordleRequest(BaseModel):
    feedback: Feedback
    language: Optional[str] = "fr"
    use_llm: Optional[bool] = False

@router.post("/guess")
def make_guess(req: WordleRequest):
    lang = (req.language or "fr").lower()
    solver = solver_fr if lang == "fr" else solver_en if lang == "en" else None
    if solver is None:
        raise HTTPException(status_code=400, detail="Langue non support√©e.")

    solver.update_constraints(req.feedback.dict())
    next_guess, explanation = solver.get_next_guess(language=lang)

    # Si LLM demand√©
    if req.use_llm:
        try:
            llm_word, llm_explanation = llm_service.suggest_word(
                candidates=solver.csp.filter_candidates(solver.constraints),
                feedback_history=[solver.constraints_dict()],
                word_length=5,
                language=lang
            )
            return {"next_guess": llm_word, "explanation": llm_explanation}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Erreur LLM Gemini : {str(e)}")

    return {"next_guess": next_guess, "explanation": explanation}

@router.post("/suggest-ai")
def suggest_with_ai(req: WordSuggestionsRequest):
    """Route d√©di√©e pour obtenir une suggestion IA bas√©e sur les contraintes actuelles"""
    print(f"üì• Requ√™te re√ßue - Language: {req.language}")
    print(f"üì• Feedback: {req.feedback.dict()}")
    
    lang = req.language.lower()
    solver = solver_fr if lang == "fr" else solver_en if lang == "en" else None
    if solver is None:
        raise HTTPException(status_code=400, detail="Langue non support√©e.")

    try:
        # √âtape 1: Mettre √† jour les contraintes
        print("üîÑ √âtape 1: Mise √† jour des contraintes...")
        solver.update_constraints(req.feedback.dict())
        print("‚úÖ Contraintes mises √† jour")
        
        # √âtape 2: Obtenir les candidats du CSP
        print("üîç √âtape 2: Filtrage des candidats...")
        candidates = solver.csp.filter_candidates(solver.constraints)
        print(f"‚úÖ {len(candidates)} candidats trouv√©s")
        
        if not candidates:
            raise HTTPException(status_code=400, detail="Aucun candidat trouv√© avec ces contraintes")
        
        # √âtape 3: Appel au LLM
        print(f"ü§ñ √âtape 3: Appel au LLM avec {min(50, len(candidates))} candidats...")
        candidates_list = list(candidates)[:50]
        print(f"Candidats envoy√©s au LLM: {candidates_list[:10]}...")
        
        llm_word, llm_explanation = llm_service.suggest_word(
            candidates=candidates_list,
            feedback_history=[],
            word_length=5,
            language=lang
        )
        
        print(f"‚úÖ LLM a r√©pondu: {llm_word}")
        
        return {
            "suggested_word": llm_word.upper(), 
            "explanation": llm_explanation,
            "candidates_count": len(candidates)
        }
        
    except HTTPException:
        raise
    except Exception as e:
        print(f"‚ùå ERREUR D√âTAILL√âE:")
        print(f"Type: {type(e).__name__}")
        print(f"Message: {str(e)}")
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Erreur : {str(e)}")